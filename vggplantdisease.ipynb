{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-15T08:42:17.163719Z",
     "iopub.status.busy": "2022-03-15T08:42:17.162895Z",
     "iopub.status.idle": "2022-03-15T08:42:17.170960Z",
     "shell.execute_reply": "2022-03-15T08:42:17.169879Z",
     "shell.execute_reply.started": "2022-03-15T08:42:17.163669Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-03-15T08:42:17.180307Z",
     "iopub.status.busy": "2022-03-15T08:42:17.179536Z",
     "iopub.status.idle": "2022-03-15T08:42:22.152151Z",
     "shell.execute_reply": "2022-03-15T08:42:22.151182Z",
     "shell.execute_reply.started": "2022-03-15T08:42:17.180259Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Input,Model\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data and Data Argumentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:42:22.154489Z",
     "iopub.status.busy": "2022-03-15T08:42:22.154046Z",
     "iopub.status.idle": "2022-03-15T08:44:04.527504Z",
     "shell.execute_reply": "2022-03-15T08:44:04.526218Z",
     "shell.execute_reply.started": "2022-03-15T08:42:22.154443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 images belonging to 38 classes.\n",
      "Found 17572 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                fill_mode='nearest')\n",
    "\n",
    "valid_gen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size=50\n",
    "base_dir=\".\\\\dataset\"\n",
    "\n",
    "training_set=train_datagen.flow_from_directory(base_dir+'/train',\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "valid_set=valid_datagen.flow_from_directory(base_dir+'/valid',\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:04.531024Z",
     "iopub.status.busy": "2022-03-15T08:44:04.529428Z",
     "iopub.status.idle": "2022-03-15T08:44:04.536898Z",
     "shell.execute_reply": "2022-03-15T08:44:04.535758Z",
     "shell.execute_reply.started": "2022-03-15T08:44:04.530971Z"
    }
   },
   "outputs": [],
   "source": [
    "train_num=training_set.samples\n",
    "valid_num=valid_set.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download VGG-16 model without Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:04.539921Z",
     "iopub.status.busy": "2022-03-15T08:44:04.539168Z",
     "iopub.status.idle": "2022-03-15T08:44:10.113961Z",
     "shell.execute_reply": "2022-03-15T08:44:10.112988Z",
     "shell.execute_reply.started": "2022-03-15T08:44:04.539864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 17s 0us/step\n",
      "58900480/58889256 [==============================] - 17s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model=tf.keras.applications.VGG16(include_top=False,\n",
    "                                      weights='imagenet',\n",
    "                                      input_shape=(224,224,3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the convolutional base created and use its as a feature extractor (by base_model.trainable=False) prevent the weights in a given layer from being updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:10.124352Z",
     "iopub.status.busy": "2022-03-15T08:44:10.124016Z",
     "iopub.status.idle": "2022-03-15T08:44:10.134011Z",
     "shell.execute_reply": "2022-03-15T08:44:10.133056Z",
     "shell.execute_reply.started": "2022-03-15T08:44:10.124320Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:10.136674Z",
     "iopub.status.busy": "2022-03-15T08:44:10.136194Z",
     "iopub.status.idle": "2022-03-15T08:44:10.154163Z",
     "shell.execute_reply": "2022-03-15T08:44:10.152567Z",
     "shell.execute_reply.started": "2022-03-15T08:44:10.136628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model by channing the base_model layer and Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:10.156299Z",
     "iopub.status.busy": "2022-03-15T08:44:10.155838Z",
     "iopub.status.idle": "2022-03-15T08:44:10.394034Z",
     "shell.execute_reply": "2022-03-15T08:44:10.393096Z",
     "shell.execute_reply.started": "2022-03-15T08:44:10.156256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 38)                19494     \n",
      "=================================================================\n",
      "Total params: 15,259,494\n",
      "Trainable params: 544,806\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs=Input(shape=(224,224,3))\n",
    "x=base_model(inputs,training=False)\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(512,activation='relu')(x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(512,activation='relu')(x)\n",
    "x=Dropout(0.2)(x)\n",
    "outputs=Dense(38,activation='softmax')(x)\n",
    "\n",
    "\n",
    "vgg_model=Model(inputs,outputs)\n",
    "\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model before training it. Since there are two classes, use a categorical cross-entropy loss & Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:10.400139Z",
     "iopub.status.busy": "2022-03-15T08:44:10.399715Z",
     "iopub.status.idle": "2022-03-15T08:44:10.419744Z",
     "shell.execute_reply": "2022-03-15T08:44:10.418705Z",
     "shell.execute_reply.started": "2022-03-15T08:44:10.400075Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vgg_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:10.422126Z",
     "iopub.status.busy": "2022-03-15T08:44:10.421413Z",
     "iopub.status.idle": "2022-03-15T08:44:10.432703Z",
     "shell.execute_reply": "2022-03-15T08:44:10.430893Z",
     "shell.execute_reply.started": "2022-03-15T08:44:10.422008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vgg_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:44:10.436196Z",
     "iopub.status.busy": "2022-03-15T08:44:10.435062Z",
     "iopub.status.idle": "2022-03-15T08:47:07.404522Z",
     "shell.execute_reply": "2022-03-15T08:47:07.403359Z",
     "shell.execute_reply.started": "2022-03-15T08:44:10.436149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 2239s 6s/step - loss: 3.7799 - accuracy: 0.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.779949188232422, 0.027202367782592773]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.evaluate(valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T08:47:07.407164Z",
     "iopub.status.busy": "2022-03-15T08:47:07.406670Z",
     "iopub.status.idle": "2022-03-15T09:12:24.046613Z",
     "shell.execute_reply": "2022-03-15T09:12:24.045666Z",
     "shell.execute_reply.started": "2022-03-15T08:47:07.407112Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\verma\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "150/150 [==============================] - 1549s 10s/step - loss: 2.6730 - accuracy: 0.2649 - val_loss: 1.6141 - val_accuracy: 0.5228\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 1647s 11s/step - loss: 1.4022 - accuracy: 0.5575 - val_loss: 1.0681 - val_accuracy: 0.6760\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 1605s 11s/step - loss: 1.0518 - accuracy: 0.6631 - val_loss: 0.8583 - val_accuracy: 0.7278\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 1531s 10s/step - loss: 0.9210 - accuracy: 0.7059 - val_loss: 0.6990 - val_accuracy: 0.7850\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 1540s 10s/step - loss: 0.8253 - accuracy: 0.7344 - val_loss: 0.6800 - val_accuracy: 0.7732\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 1681s 11s/step - loss: 0.7499 - accuracy: 0.7537 - val_loss: 0.6645 - val_accuracy: 0.7812\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 1754s 12s/step - loss: 0.7055 - accuracy: 0.7717 - val_loss: 0.6258 - val_accuracy: 0.8048\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 1711s 11s/step - loss: 0.6568 - accuracy: 0.7867 - val_loss: 0.5714 - val_accuracy: 0.8118\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 1802s 12s/step - loss: 0.6469 - accuracy: 0.7839 - val_loss: 0.5418 - val_accuracy: 0.8246\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 1793s 12s/step - loss: 0.6245 - accuracy: 0.7883 - val_loss: 0.5122 - val_accuracy: 0.8338\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 1973s 13s/step - loss: 0.5820 - accuracy: 0.8056 - val_loss: 0.5580 - val_accuracy: 0.8114\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 1855s 12s/step - loss: 0.5708 - accuracy: 0.8091 - val_loss: 0.4956 - val_accuracy: 0.8384\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 1584s 11s/step - loss: 0.5715 - accuracy: 0.8129 - val_loss: 0.5107 - val_accuracy: 0.8270\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 1667s 11s/step - loss: 0.5590 - accuracy: 0.8165 - val_loss: 0.4618 - val_accuracy: 0.8484\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 1645s 11s/step - loss: 0.5112 - accuracy: 0.8313 - val_loss: 0.4797 - val_accuracy: 0.8426\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "weightpath='best_weights_9.hdf5'\n",
    "checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, save_weights_only=True, mode='max')\n",
    "\n",
    "history=vgg_model.fit_generator(training_set,\n",
    "                        steps_per_epoch=150,\n",
    "                        epochs=15,\n",
    "                        validation_data=valid_set,\n",
    "                        validation_steps=100,\n",
    "                        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T09:12:24.050746Z",
     "iopub.status.busy": "2022-03-15T09:12:24.050394Z",
     "iopub.status.idle": "2022-03-15T09:34:11.893216Z",
     "shell.execute_reply": "2022-03-15T09:34:11.892225Z",
     "shell.execute_reply.started": "2022-03-15T09:12:24.050698Z"
    }
   },
   "outputs": [],
   "source": [
    "history=vgg_model.fit_generator(training_set,\n",
    "                        steps_per_epoch=150,\n",
    "                        epochs=15,\n",
    "                        validation_data=valid_set,\n",
    "                        validation_steps=100,\n",
    "                        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T09:34:11.896906Z",
     "iopub.status.busy": "2022-03-15T09:34:11.896037Z",
     "iopub.status.idle": "2022-03-15T09:54:56.447969Z",
     "shell.execute_reply": "2022-03-15T09:54:56.447063Z",
     "shell.execute_reply.started": "2022-03-15T09:34:11.896856Z"
    }
   },
   "outputs": [],
   "source": [
    "history=vgg_model.fit_generator(training_set,\n",
    "                        steps_per_epoch=150,\n",
    "                        epochs=15,\n",
    "                        validation_data=valid_set,\n",
    "                        validation_steps=100,\n",
    "                        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the feature extraction experiment, you were only training a few layers on top of an VGG-16 base model. The weights of the pre-trained network were not updated during training.\n",
    "\n",
    "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n",
    "\n",
    " The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T09:54:56.452147Z",
     "iopub.status.busy": "2022-03-15T09:54:56.451816Z",
     "iopub.status.idle": "2022-03-15T09:54:56.469178Z",
     "shell.execute_reply": "2022-03-15T09:54:56.464701Z",
     "shell.execute_reply.started": "2022-03-15T09:54:56.452099Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model.trainable=True #Un-Freezing the base model\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-15T09:54:56.473982Z",
     "iopub.status.busy": "2022-03-15T09:54:56.473643Z",
     "iopub.status.idle": "2022-03-15T10:09:58.082379Z",
     "shell.execute_reply": "2022-03-15T10:09:58.081447Z",
     "shell.execute_reply.started": "2022-03-15T09:54:56.473952Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "fine_tune_history=vgg_model.fit_generator(training_set,\n",
    "                                        steps_per_epoch=150,\n",
    "                                        validation_data=valid_set,\n",
    "                                        epochs=10,\n",
    "                                        validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vgg_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\verma\\AppData\\Local\\Temp/ipykernel_2596/2051270564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvgg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vgg_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
